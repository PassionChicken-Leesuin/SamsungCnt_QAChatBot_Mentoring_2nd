import os
import requests
import pandas as pd
from dotenv import load_dotenv
from datetime import datetime

# .env ë¡œë“œ
load_dotenv()

# .env ì— SERPAPI_API_KEY=... í˜•íƒœë¡œ ë“¤ì–´ìˆë‹¤ê³  ê°€ì •
SERPAPI_KEY = os.getenv("SERPAPI_API_KEY")


def fetch_serpapi_news(
    query: str = "ì‚°ì—… ì•ˆì „ ì‚¬ê³ ",
    num: int = 10,
    debug: bool = False
) -> dict:
    """
    SerpAPI ê¸°ë°˜ Google News ê²€ìƒ‰

    Parameters
    ----------
    query : str
        ê²€ìƒ‰ì–´ (ì˜ˆ: 'ì‚°ì—… ì•ˆì „ ì‚¬ê³ ')
    num : int
        ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê°œìˆ˜ (SerpAPIì˜ num íŒŒë¼ë¯¸í„° ê·¸ëŒ€ë¡œ ì‚¬ìš©)
    debug : bool
        Trueì¼ ê²½ìš° ìƒíƒœì½”ë“œ / ìš”ì²­ URL / ì‘ë‹µ ì¼ë¶€ ì¶œë ¥

    Returns
    -------
    dict
        SerpAPI JSON ì‘ë‹µ
    """

    if SERPAPI_KEY is None:
        raise ValueError("â— SERPAPI_API_KEYê°€ .envì— ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤!")

    url = "https://serpapi.com/search"

    params = {
        "engine": "google_news",
        "q": query,
        "api_key": SERPAPI_KEY,
        "num": num,      # ğŸ”¥ ì—¬ê¸° ê°’ì´ max_items ê·¸ëŒ€ë¡œ ë°˜ì˜ë¨
        "gl": "kr",
        "hl": "ko",
    }

    resp = requests.get(url, params=params)

    if debug:
        print("ğŸ” status:", resp.status_code)
        print("ğŸ” ìš”ì²­ URL:", resp.url)
        print("\n----- ì‘ë‹µ ì›ë¬¸ (ì• 500ì) -----")
        print(resp.text[:500])

    resp.raise_for_status()
    return resp.json()


# ğŸ”¥ SerpAPI ë‚ ì§œ í¬ë§· ì „ìš© íŒŒì„œ
def parse_serpapi_date(date_str):
    """
    ì˜ˆì‹œ: '11/25/2025, 01:47 AM, +0000 UTC'
    â†’ datetime ê°ì²´ë¡œ ë³€í™˜
    """
    if not isinstance(date_str, str):
        return None

    # ' UTC' ì œê±° â†’ '11/25/2025, 01:47 AM, +0000'
    cleaned = date_str.replace(" UTC", "")

    # í¬ë§·: MM/DD/YYYY, HH:MM AM/PM, +0000
    try:
        return datetime.strptime(cleaned, "%m/%d/%Y, %I:%M %p, %z")
    except Exception:
        return None


def serpapi_to_df(data: dict) -> pd.DataFrame:
    """
    SerpAPI Google News JSON â†’ DataFrame ë³€í™˜

    Parameters
    ----------
    data : dict
        fetch_serpapi_news ì‘ë‹µ JSON

    Returns
    -------
    DataFrame
        title / url / published / content / source ê°€ ë‹´ê¸´ DataFrame
        (ì—†ëŠ” ì»¬ëŸ¼ì€ ìë™ìœ¼ë¡œ ì œì™¸)
    """

    items = data.get("news_results", [])
    if not items:
        return pd.DataFrame()

    df = pd.DataFrame(items)

    # source ì»¬ëŸ¼ì´ dict í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì´ë¦„ë§Œ ì¶”ì¶œ
    if "source" in df.columns:
        df["source"] = df["source"].apply(
            lambda s: s.get("name") if isinstance(s, dict) else s
        )

    # ê³µí†µ ì»¬ëŸ¼ëª…ìœ¼ë¡œ í†µì¼
    rename_map = {}
    if "link" in df.columns:
        rename_map["link"] = "url"
    if "date" in df.columns and "published" not in df.columns:
        rename_map["date"] = "published"
    if "snippet" in df.columns and "content" not in df.columns:
        rename_map["snippet"] = "content"

    if rename_map:
        df = df.rename(columns=rename_map)

    # ğŸ” ë””ë²„ê·¸: ì›ë³¸ published ë¬¸ìì—´ í™•ì¸
    if "published" in df.columns:
        print("[SERPAPI DEBUG] published raw head ===")
        print(df["published"].head())
        print("[SERPAPI DEBUG] published raw dtype:", df["published"].dtype)

        # ğŸ”¥ ì—¬ê¸°ì„œ ì§ì ‘ íŒŒì‹± (ì ˆëŒ€ pd.to_datetime() ë‹¤ì‹œ ì“°ì§€ ì•Šê¸°!)
        df["published"] = df["published"].apply(parse_serpapi_date)

        print("\n[SERPAPI DEBUG] published parsed head ===")
        print(df["published"].head())
        print("[SERPAPI DEBUG] published parsed dtype:", df["published"].dtype)

    # ìµœì¢…ì ìœ¼ë¡œ ìì£¼ ì“°ëŠ” ì»¬ëŸ¼ë§Œ ì •ë¦¬í•´ì„œ ë°˜í™˜
    cols = ["title", "url", "published", "content", "source"]
    cols = [c for c in cols if c in df.columns]

    return df[cols]
